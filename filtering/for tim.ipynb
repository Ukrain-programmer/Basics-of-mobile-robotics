{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58770a5d-a7cb-4e9a-b0cf-cd1bf7e6fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "def euler_from_rvec(rvec):\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    \n",
    "    # Calculate Euler angles (roll, pitch, yaw)\n",
    "    pitch = np.arctan2(R[2, 0], np.sqrt(R[0, 0]**2 + R[1, 0]**2))\n",
    "    roll = np.arctan2(R[2, 1], R[2, 2])\n",
    "    yaw = np.degrees(np.arctan2(R[1, 0], R[0, 0]))\n",
    "    if yaw >-180 and yaw < 0:\n",
    "        yaw=abs(yaw)\n",
    "    else:\n",
    "        yaw=360-yaw\n",
    "        \n",
    "    return roll, pitch, yaw\n",
    " \n",
    "def draw_trajectory(img, odom_position, color=(0, 255, 255), thickness=10):\n",
    "    for k in range(1, len(odom_position)):\n",
    "        start_point = tuple(odom_position[k-1][:2])  # First two elements of the previous position\n",
    "        end_point = tuple(odom_position[k][:2])     # First two elements of the current position\n",
    "        cv2.line(img, start_point, end_point, color, thickness)\n",
    "\n",
    "def update_odom_position(odom_tvec, marker_corners_3d, newcameramtx, dist, period,centers,yaw,initial,flag):\n",
    "    \n",
    "    odom_rvec=  np.array([[0.], [0.], [0.]])\n",
    "    #odom_tvec,yaw = update_position(odom_tvec, odom_rvec,period,yaw,initial) \n",
    "    #next_time, x_updated, P_updated, x_predicted = kf.kalman_filter(flag, u, z)\n",
    "    \n",
    "    # Convert odometry vectors to the appropriate format\n",
    "    odom_tvec = np.array(odom_tvec, dtype=np.float64).reshape(3, 1)\n",
    "    odom_rvec = np.array(odom_rvec, dtype=np.float64).reshape(3, 1)\n",
    "\n",
    "\n",
    "    \n",
    "    projected_points_odom, _ = cv2.projectPoints(marker_corners_3d,odom_rvec,odom_tvec,newcameramtx, dist)\n",
    "    projected_points_odom = projected_points_odom.reshape(-1, 2).astype(int)\n",
    "\n",
    "    # Compute the center of the projected points\n",
    "    center_odom = np.mean(projected_points_odom, axis=0).astype(int)\n",
    "    centers.append(center_odom)\n",
    "    return odom_tvec, odom_rvec, center_odom, period,centers,yaw\n",
    "import cv2\n",
    "\n",
    "def draw_marker_paths(img, marker_centers, marker_id, center, circle_color=(0, 0, 255), line_color=(255, 0, 0), circle_radius=5, line_thickness=2, window_name=\"Marker Path Tracking\"):\n",
    "\n",
    "    cv2.circle(img, tuple(center), circle_radius, circle_color, -1)\n",
    "    if len(marker_centers[marker_id]) > 1:\n",
    "        for j in range(1, len(marker_centers[marker_id])):\n",
    "            cv2.line(img, tuple(marker_centers[marker_id][j-1]), tuple(marker_centers[marker_id][j]), line_color, line_thickness)\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow(window_name, img)\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "from cv2 import aruco\n",
    "\n",
    "def initialize_camera_and_calibration(calibration_file = 'calibration.yaml', camera_index=1, aruco_dict_type=aruco.DICT_6X6_1000):\n",
    "    with open(calibration_file, 'r') as f:\n",
    "        calibration_data = yaml.safe_load(f)\n",
    "\n",
    "    mtx = np.array(calibration_data['camera_matrix'])\n",
    "    dist = np.array(calibration_data['dist_coeff'])\n",
    "\n",
    "    # Load the ArUco dictionary and parameters\n",
    "    aruco_dict = aruco.getPredefinedDictionary(aruco_dict_type)\n",
    "    aruco_params = aruco.DetectorParameters()\n",
    "\n",
    "    # Initialize the camera\n",
    "    camera = cv2.VideoCapture(camera_index)\n",
    "    if not camera.isOpened():\n",
    "        raise RuntimeError(\"Error: Could not open the camera.\")\n",
    "\n",
    "    # Read a frame to determine the image size\n",
    "    ret, img = camera.read()\n",
    "    if not ret:\n",
    "        raise RuntimeError(\"Error: Could not read from the camera.\")\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Get the optimal camera matrix\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n",
    "\n",
    "    return camera, aruco_dict, aruco_params, newcameramtx, dist, mtx\n",
    "def detect_marker_with_id(frame, aruco_dict, aruco_params, target_id=10):\n",
    "    robot_detected=False\n",
    "    # Detect markers in the frame\n",
    "    corners, ids, rejected_img_points = aruco.detectMarkers(frame, aruco_dict, parameters=aruco_params)\n",
    "\n",
    "    if ids is not None:\n",
    "        for i, marker_id in enumerate(ids.flatten()):\n",
    "            if marker_id == target_id:\n",
    "                \n",
    "                return corners[i], marker_id, True\n",
    "\n",
    "    # Return None if the target ID is not found\n",
    "    return None,None,False\n",
    "def process_marker(corners, marker_id, target_id, camera_matrix, dist_coeffs,marker_centers):\n",
    "    \n",
    "    if marker_id != target_id:\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Get the 2D positions of the marker corners\n",
    "    marker_2d = corners[0]\n",
    "\n",
    "    # Define the 3D positions of the marker corners in the world frame\n",
    "    marker_corners_3d = np.array([\n",
    "        [-0.45, -0.45, 0],\n",
    "        [0.45, -0.45, 0],\n",
    "        [0.45, 0.45, 0],\n",
    "        [-0.45, 0.45, 0]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    # Solve PnP to find rotation and translation vectors\n",
    "    _, rvec_marker, tvec_marker = cv2.solvePnP(marker_corners_3d, marker_2d, camera_matrix, dist_coeffs)\n",
    "\n",
    "    # Project the 3D points to 2D\n",
    "    projected_points, _ = cv2.projectPoints(marker_corners_3d, rvec_marker, tvec_marker, camera_matrix, dist_coeffs)\n",
    "    projected_points = projected_points.reshape(-1, 2).astype(int)\n",
    "\n",
    "    # Calculate the center of the marker\n",
    "    center = tuple(np.mean(projected_points, axis=0).astype(int))\n",
    "    marker_centers.append(center)\n",
    "    \n",
    "    return center, projected_points, tvec_marker, rvec_marker, marker_centers,marker_corners_3d\n",
    "def draw_marker_path(image, marker_centers, color=(255, 0, 0), thickness=2):\n",
    "    cv2.circle(image, tuple(center), 5, (0, 0, 255), -1)\n",
    "\n",
    "    if len(marker_centers) > 1:\n",
    "        for j in range(1, len(marker_centers)):\n",
    "            cv2.line(image, tuple(marker_centers[j-1]), tuple(marker_centers[j]), color, thickness)\n",
    "    return image\n",
    "def get_z(rvec,center):\n",
    "    roll,pitch,yaw = euler_from_rvec(rvec)\n",
    "    \n",
    "    return [center[0],center[1],np.round((yaw))]\n",
    "    \n",
    "def update_position(tvec,period,theta,initial_tz):\n",
    "    period=np.round(period,8)\n",
    "    #print(period)\n",
    "    '''\n",
    "    if period < 0.000001:\n",
    "        time.sleep(0.000001-period)\n",
    "    '''\n",
    "    if (period < 0.02):  \n",
    "        dt = 0.02\n",
    "    dt=period*(conversion_factor/2)\n",
    "    \n",
    "    #rvec = np.array(rvec, dtype=np.float64)\n",
    "    # Unpack current position (x, y, theta)\n",
    "    #dt=0.0001\n",
    "    #v = (motor_left_speed + motor_right_speed) / 2\n",
    "    #v =v/0.3870967741935484\n",
    "    #ls=motor_left_speed\n",
    "    #rs=motor_right_speed\n",
    "    ls,rs=speeds()\n",
    "    #print(ls,rs)\n",
    "    #print(tvec)\n",
    "    x, y,_= tvec\n",
    "    robot_length=1.1\n",
    "    #theta=get_theta_from_rvec_and_tvec(tvec,rvec)\n",
    "    #theta=0\n",
    "    # Compute the change in position using the odometry equations\n",
    "    delta_x = (0.5 * dt * np.cos(theta) * ls + 0.5 * dt * np.cos(theta) * rs )\n",
    "    delta_y =(-0.5 * dt * np.sin(theta) * ls + -0.5 * dt * np.sin(theta) * rs )\n",
    "    delta_theta = (-dt / robot_length) * ls + (dt / robot_length) * rs\n",
    "    #print(delta_theta)\n",
    "    new_theta=delta_theta+theta\n",
    "    print(np.round(np.degrees(new_theta),3))\n",
    "    updated_tvec = [x +delta_x, y + delta_y,np.array([ initial_tz])]\n",
    "    return updated_tvec,new_theta\n",
    "\n",
    "def warp_and_threshold(frame, rect_corners, width=600, height=800):\n",
    "\n",
    "    # Define destination points for the flattened rectangle\n",
    "    dst_corners = np.array([\n",
    "        [0, 0],\n",
    "        [width - 1, 0],\n",
    "        [width - 1, height - 1],\n",
    "        [0, height - 1]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    # Compute the perspective transform matrix\n",
    "    matrix = cv2.getPerspectiveTransform(rect_corners, dst_corners)\n",
    "\n",
    "    # Apply perspective warp to get the top-down view\n",
    "    warped_image = cv2.warpPerspective(frame, matrix, (width, height))\n",
    "\n",
    "    return warped_image\n",
    "import cv2\n",
    "\n",
    "def resize_image(image, new_width=60):\n",
    "\n",
    "    # Get the original dimensions of the image\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Calculate the new height to maintain the aspect ratio\n",
    "    new_height = int((new_width / width) * height)\n",
    "    \n",
    "    # Resize the image using nearest neighbor interpolation\n",
    "    resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    return resized_image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def map_and_draw_path(image,matplotlib_points, matplotlib_size, opencv_size, image_color=(0, 0, 0), path_color=(255, 0, 0), thickness=2):\n",
    "    \n",
    "    matplotlib_width, matplotlib_height = matplotlib_size\n",
    "    opencv_width, opencv_height = opencv_size\n",
    "    \n",
    "\n",
    "    # Scale points to OpenCV space (invert y-axis)\n",
    "    points_cv = [\n",
    "        (int(x / matplotlib_width * opencv_width), int(opencv_height - (y / matplotlib_height * opencv_height)))\n",
    "        for x, y in matplotlib_points\n",
    "    ]\n",
    "\n",
    "    # Draw the path\n",
    "    for i in range(1, len(points_cv)):\n",
    "        cv2.line(image, points_cv[i - 1], points_cv[i], path_color, thickness)\n",
    "\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319fe5a0-e653-437e-b5d7-7054b4af60c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m initial_tz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     22\u001b[0m rect_corners \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m125\u001b[39m, \u001b[38;5;241m123\u001b[39m], [\u001b[38;5;241m544\u001b[39m, \u001b[38;5;241m128\u001b[39m], [\u001b[38;5;241m582\u001b[39m,\u001b[38;5;241m340\u001b[39m], [\u001b[38;5;241m89\u001b[39m, \u001b[38;5;241m343\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 24\u001b[0m path \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mpoints\u001b[49m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m     26\u001b[0m marker_corners_3d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'points' is not defined"
     ]
    }
   ],
   "source": [
    "camera, aruco_dict, aruco_params, newcameramtx, dist, mtx =initialize_camera_and_calibration()\n",
    "odom_position=[]\n",
    "first=False\n",
    "odom_tvec=[0.,0.,0.]\n",
    "# Processing loop\n",
    "current_time=time.time()\n",
    "\n",
    "period=0\n",
    "yaw_odom=0\n",
    "yaw_aruco=0\n",
    "marker_centers=[]\n",
    "odom_centers=[]\n",
    "z=[0,0,0]\n",
    "initial=False\n",
    "yaw=0\n",
    "kidnapped=False\n",
    "conversion_factor = 0.3870967741935484 \n",
    "odom_tvec=0\n",
    "odom_rvec=np.array([[0.],[0.],[0.]])\n",
    "tvec_marker=np.array([[0.],[0.],[0.]])\n",
    "initial_tz=0\n",
    "rect_corners = np.array([[125, 123], [544, 128], [582,340], [89, 343]], dtype=np.float32)\n",
    "\n",
    "import time\n",
    "marker_corners_3d=0\n",
    "print(\"Press 'q' to exit.\")\n",
    "while True:\n",
    "    ret, img = camera.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read from the camera.\")\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Undistort the image\n",
    "    dst = cv2.undistort(img_gray, mtx, dist, None, newcameramtx)\n",
    "    corners,marker_id, robot_detected = detect_marker_with_id(dst, aruco_dict, aruco_params, target_id=5)\n",
    "\n",
    "    if robot_detected:\n",
    "        # Draw the detected marker\n",
    "        aruco.drawDetectedMarkers(img, [corners],np.array([marker_id]), (0, 255, 0))\n",
    "        center, projected_points, tvec_marker, rvec_marker ,marker_centers,marker_corners_3d= process_marker(corners, marker_id, 5, newcameramtx, dist,marker_centers)\n",
    "        z = get_z( rvec_marker,center )\n",
    "        \n",
    "        \n",
    "        if not initial or kidnapped :\n",
    "            \n",
    "            odom_tvec = tvec_marker\n",
    "            odom_centers.append(center)\n",
    "            initial_tz=odom_tvec[2][0]\n",
    "            odom_tvec, odom_rvec, center_odom, period,odom_centers,yaw_odom = update_odom_position(odom_tvec, marker_corners_3d, newcameramtx, dist, period,odom_centers,0,initial_tz)\n",
    "            initial=True\n",
    "            \n",
    "            end_time = time.time()\n",
    "            period = end_time - current_time\n",
    "    else:\n",
    "        print(\"robot not found.\")        \n",
    "    if initial:\n",
    "        \n",
    "        current_time=time.time()\n",
    "        odom_tvec, odom_rvec, center_odom, period,odom_centers ,yaw_odom= update_odom_position(odom_tvec, marker_corners_3d, newcameramtx, dist, period,odom_centers,yaw_odom,initial_tz)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        period = end_time - current_time\n",
    "            \n",
    "\n",
    "\n",
    "    # Show the frame\n",
    "    draw_trajectory(img,odom_centers)\n",
    "    cv2.putText(img, \"yaw aruco\"+str(z[2]), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img, \"yaw\"+str(np.degrees(yaw_odom)), (400, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    draw_marker_path(img, marker_centers)\n",
    "    \n",
    "    cv2.imshow(\"ArUco Detection\", img)\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    warped=warp_and_threshold(img,rect_corners)\n",
    "   \n",
    "    for i in range(1, len(path)):\n",
    "        cv2.line(warped, tuple(path[i - 1]), tuple(path[i]), (255, 0, 0), 1)\n",
    "\n",
    "    \n",
    "    matplotlib_size = (800, 600)\n",
    "    opencv_size = (800, 600)\n",
    "    \n",
    "    # Generate the image\n",
    "    path_image = map_and_draw_path(warped,path, matplotlib_size, opencv_size)\n",
    "    cv2.imshow(\"warped\",warped )\n",
    "    '''\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        motors(0, 0, verbose=True)\n",
    "        break\n",
    "    time.sleep(0.0003)\n",
    "#camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd387709-52df-4b0f-9564-92b1e590c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import datetime\n",
    "from cv2 import aruco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ec486-130a-4e4b-9f66-d375cb081d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ARUCO dictionary to detect\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "\n",
    "#Initialize the video capture (0 for computer camera)\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame\")\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale for detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect ArUco markers\n",
    "    corners, ids, rejected = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "    if ids is not None and len(ids) >= 4:  # Ensure at least 4 markers are detected\n",
    "        # Draw detected markers for visualization\n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "        # Collect the corners of the 4 markers\n",
    "        marker_corners = {}\n",
    "        for i, marker_id in enumerate(ids.flatten()):\n",
    "            marker_corners[marker_id] = corners[i][0]  # Extract the corners for each detected marker\n",
    "\n",
    "        # Check if specific 4 marker IDs are detected (e.g., IDs 0, 1, 2, 3)\n",
    "        required_ids = [0, 1, 2, 3]\n",
    "        if all(marker_id in marker_corners for marker_id in required_ids):\n",
    "            # Get the centers of the 4 markers\n",
    "            centers = {marker_id: np.mean(marker_corners[marker_id], axis=0) for marker_id in required_ids}\n",
    "\n",
    "            # Sort the points for consistent perspective correction\n",
    "            # Top-left, top-right, bottom-right, bottom-left order\n",
    "            sorted_ids = sorted(centers.items(), key=lambda x: (x[1][1], x[1][0]))  # Sort by Y, then by X\n",
    "            sorted_points = [x[1] for x in sorted_ids]  # Extract the points in sorted order\n",
    "\n",
    "            # Create source and destination points for perspective transform\n",
    "            src_points = np.array(sorted_points, dtype=\"float32\")\n",
    "            dst_points = np.array([[0, 0], [500, 0], [500, 500], [0, 500]], dtype=\"float32\")\n",
    "\n",
    "            # Compute the perspective transform matrix\n",
    "            matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "            # Warp the perspective to get the focused rectangle\n",
    "            warped = cv2.warpPerspective(frame, matrix, (500, 500))\n",
    "\n",
    "            # Display the warped image (focused rectangle)\n",
    "            cv2.imshow(\"Warped View\", warped)\n",
    "\n",
    "    # Display the original frame with detected markers\n",
    "    cv2.imshow(\"Original Frame\", frame)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52b9382a-743e-4aec-8400-b7ef86d9d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_smoothing(img, sc = 1000, ss = 3000, diameter = 20):\n",
    "    smooth_img = cv2.bilateralFilter(img, d=diameter, sigmaColor = sc, sigmaSpace = ss)\n",
    "    return smooth_img\n",
    "\n",
    "def image_hsv(img):\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    return img_hsv\n",
    "\n",
    "def get_obstacles(frame):\n",
    "    img_copy = frame.copy()\n",
    "\n",
    "    #1) Convert to HSV\n",
    "    img_hsv = image_hsv(img_copy)\n",
    "\n",
    "    #2) Smooth image to remove noise and smoothen the gradiant\n",
    "    img_smooth = image_smoothing(img_hsv)\n",
    "\n",
    "    #3) Mask for obstacles\n",
    "    #obstaces colour (black). Colour red when detected\n",
    "    obst_bound = np.array([[0, 0, 0], [180,220,90], [0, 0 , 255]])\n",
    "    min_bound = np.array(obst_bound[0], np.uint8)\n",
    "    max_bound = np.array(obst_bound[1], np.uint8)\n",
    "    img_masked = cv2.inRange(img_smooth, min_bound, max_bound)\n",
    "    \n",
    "\n",
    "    #4) obstacle detection\n",
    "    contours, _ = cv2.findContours(img_masked, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "\n",
    "image_path = \"output_frame.jpg\" \n",
    "\n",
    "#cap = cv2.VideoCapture(0)\n",
    "#ret, frame = cap.read()\n",
    "\n",
    "frame = cv2.imread(image_path)\n",
    "contours = get_obstacles(frame)\n",
    "# Display the result\n",
    "cv2.drawContours(frame, contours, -1, (0, 255, 0), 1)\n",
    "cv2.imshow(\"Corrected Rectangle\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e6f49-220a-4529-8f2e-d1a202fe1623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f61439-f438-4803-be33-67d8f3a25dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da45b2d-a6fb-4ae3-afdd-690e4205d8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
